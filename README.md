<div align="center">

# llama.rust   
LLM inference in Rust

[![Version](https://img.shields.io/crates/v/llama-rust)](https://crates.io/crates/llama-rust)
[![Crates Downloads](https://img.shields.io/crates/d/llama-rust?logo=rust)](https://crates.io/crates/llama-rust)

</div>

## Usage
```bash
cargo run --release -- --model "meta-llama/Llama-3.2-1B" --prompt "What is the capital of France?" --max-tokens 20 --temperature 0.7
```

